{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pydicom\n",
    "import glob\n",
    "import cv2\n",
    "import tqdm\n",
    "from scipy.ndimage.morphology import binary_dilation\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "batch_size = 1\n",
    "input_dir = '../../input'\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(input_dir, 'sample_submission.csv'))\n",
    "test_df['ImagePath'] = test_df['ImageId'].apply(lambda x : os.path.join(input_dir, 'test', x) + '.dcm')\n",
    "test_df[' EncodedPixels'] = [' -1']*test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 df, \n",
    "                 tfms = None):\n",
    "\n",
    "        self.df = df\n",
    "        self.ids_list = self.df[\"ImageId\"].unique()\n",
    "\n",
    "        self.tfms = tfms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids_list[idx]\n",
    "\n",
    "        df_masks = self.df[self.df[\"ImageId\"] == img_id]\n",
    "        img_path = df_masks.iloc[0][\"ImagePath\"]\n",
    "\n",
    "        img = pydicom.read_file(img_path).pixel_array\n",
    "        segm = np.zeros_like(img)\n",
    "\n",
    "        img = np.repeat(np.expand_dims(img, axis=2), 3, axis=2)\n",
    "\n",
    "        if df_masks.iloc[0][' EncodedPixels'] != ' -1':\n",
    "            for i in range(len(df_masks)):\n",
    "                segm += rle2mask(df_masks.iloc[i][' EncodedPixels'], img.shape[0], img.shape[1]).astype(np.uint8).T\n",
    "\n",
    "        segm = np.expand_dims(segm, axis=2)\n",
    "\n",
    "        data = {\"image\": img, \"mask\": segm}\n",
    "\n",
    "        augmented = self.tfms(**data)\n",
    "        img, segm = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "        return transforms.ToTensor()(img), transforms.ToTensor()(segm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import Resize, Compose, Normalize, ShiftScaleRotate\n",
    "\n",
    "def get_segm_dl(img_size):\n",
    "    tfms_val = Compose([\n",
    "        Resize(img_size, img_size),\n",
    "        Normalize(mean=(0.49, 0.49, 0.49), std=(0.235, 0.235, 0.235), max_pixel_value=255.0, always_apply=True, p=1.0)\n",
    "    ], p=1.0)\n",
    "    test_ds = SegmentationDataset(test_df, tfms = tfms_val)\n",
    "    test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return test_dl\n",
    "\n",
    "tfms_val_class = Compose([\n",
    "    Resize(768, 768),\n",
    "    Normalize(mean=(0.49, 0.49, 0.49), std=(0.235, 0.235, 0.235), max_pixel_value=255.0, always_apply=True, p=1.0)\n",
    "], p=1.0)\n",
    "\n",
    "tfms_val_tta_class = Compose([\n",
    "    Resize(512, 512),\n",
    "    ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, interpolation=1, border_mode=0, always_apply=False, p=1.0),\n",
    "    Normalize(mean=(0.49, 0.49, 0.49), std=(0.235, 0.235, 0.235), max_pixel_value=255.0, always_apply=True, p=1.0)\n",
    "], p=1.0)\n",
    "\n",
    "#holdout_ds = SegmentationDataset(df, tfms = tfms_val)\n",
    "#holdout_ds_class = SegmentationDataset(df, tfms = tfms_val_class)\n",
    "#holdout_ds_class_tta = SegmentationDataset(df, tfms = tfms_val_tta_class)\n",
    "\n",
    "test_ds_class = SegmentationDataset(test_df, tfms = tfms_val_class)\n",
    "test_ds_class_tta = SegmentationDataset(test_df, tfms = tfms_val_tta_class)\n",
    "\n",
    "#holdout_dl = torch.utils.data.DataLoader(holdout_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "#holdout_dl_class = torch.utils.data.DataLoader(holdout_ds_class, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "#holdout_dl_class_tta = torch.utils.data.DataLoader(holdout_ds_class_tta, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "test_dl_class = torch.utils.data.DataLoader(test_ds_class, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_dl_class_tta = torch.utils.data.DataLoader(test_ds_class_tta, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "\n",
    "tfms_val = Compose([\n",
    "    Resize(img_size, img_size),\n",
    "    Normalize(mean=(0.49, 0.49, 0.49), std=(0.235, 0.235, 0.235), max_pixel_value=255.0, always_apply=True, p=1.0)\n",
    "], p=1.0)\n",
    "test_ds = SegmentationDataset(test_df, tfms = tfms_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fake_segmentation_models:\n",
    "    class SENet154(nn.Module):\n",
    "        def __init__(self, num_classes, pretrained=True, dropout=0.5):\n",
    "            super(SENet154, self).__init__()\n",
    "            self.encoder = pretrainedmodels.models.senet.senet154()\n",
    "\n",
    "            self.encoder.dropout = nn.Dropout(dropout)\n",
    "            self.encoder.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "            self.encoder.last_linear = nn.Linear(2048, num_classes)\n",
    "\n",
    "        def forward(self, x): \n",
    "            x = self.encoder(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    class SEResNetx101_32(nn.Module):\n",
    "        def __init__(self, num_classes, pretrained=True, dropout=0.5):\n",
    "            super(SEResNetx101_32, self).__init__()\n",
    "            self.encoder = pretrainedmodels.models.senet.se_resnext101_32x4d()\n",
    "\n",
    "            self.encoder.dropout = nn.Dropout(dropout)\n",
    "            self.encoder.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "            self.encoder.last_linear = nn.Linear(2048, num_classes)\n",
    "\n",
    "        def forward(self, x): \n",
    "            x = self.encoder(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "sys.modules[\"segmentation\"] = None\n",
    "sys.modules[\"segmentation.models\"] = Fake_segmentation_models\n",
    "#sys.modules[\"segmentation.models.SENet154\"] = SENet154\n",
    "\n",
    "    \n",
    "class CBlendModel( nn.Module ):\n",
    "    def __init__(self, models, ths):\n",
    "        super(CBlendModel, self).__init__()\n",
    "        self.models = models\n",
    "        self.x = torch.nn.Parameter(torch.ones(len(self.models), requires_grad=True) / len(self.models))\n",
    "        self.ths = ths\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        n = len(self.models)\n",
    "        output = 0\n",
    "        \n",
    "        for i in range(n):\n",
    "            with torch.no_grad():\n",
    "                self.models[i].eval()\n",
    "                tmp = self.models[i](inputs)#.exp()\n",
    "                #tmp = tmp/(1+tmp)\n",
    "\n",
    "                tmp_flip = self.models[i](torch.flip(inputs, dims=(3,)))#.exp()\n",
    "                #tmp_flip = tmp_flip/(1+tmp_flip)\n",
    "                tmp = (tmp + tmp_flip)/2\n",
    "                out = tmp * self.x[i]\n",
    "                #out = (tmp > 1.0) * 1.0\n",
    "                \n",
    "            output += out  #/ self.x.sum()\n",
    "    \n",
    "        return output\n",
    "    \n",
    "class_model = torch.load(\"cblend_rex101_2x_senet154.pth\", map_location=\"cpu\")\n",
    "class_model = class_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(class_model.models)):\n",
    "    class_model.models[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import re\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "class Fake_Module_resnetx:\n",
    "    def conv3x3(in_planes, out_planes, stride=1):\n",
    "        \"\"\"3x3 convolution with padding\"\"\"\n",
    "        return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                         padding=1, bias=False)\n",
    "\n",
    "    class ConvBn2d(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)):\n",
    "            super(ConvBn2d, self).__init__()\n",
    "\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                  bias=False)\n",
    "            self.bn = nn.BatchNorm2d(out_channels)\n",
    "            # self.bn = SynchronizedBatchNorm2d(out_channels)\n",
    "\n",
    "        def forward(self, z):\n",
    "            x = self.conv(z)\n",
    "            x = self.bn(x)\n",
    "            return x\n",
    "\n",
    "\n",
    "    class ConvRelu(nn.Module):\n",
    "        def __init__(self, in_, out):\n",
    "            super().__init__()\n",
    "            self.conv = conv3x3(in_, out)\n",
    "            self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv(x)\n",
    "            x = self.activation(x)\n",
    "            return x\n",
    "\n",
    "\n",
    "    class DecoderBlockV2(nn.Module):\n",
    "        def __init__(self, in_channels, middle_channels, out_channels, is_deconv=True):\n",
    "            super(DecoderBlockV2, self).__init__()\n",
    "            self.in_channels = in_channels\n",
    "\n",
    "            if is_deconv:\n",
    "                \"\"\"\n",
    "                    Paramaters for Deconvolution were chosen to avoid artifacts, following\n",
    "                    link https://distill.pub/2016/deconv-checkerboard/\n",
    "                \"\"\"\n",
    "\n",
    "                self.block = nn.Sequential(\n",
    "                    ConvRelu(in_channels, middle_channels),\n",
    "                    nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=4, stride=2,\n",
    "                                       padding=1),\n",
    "                    nn.ReLU(inplace=True))\n",
    "            else:\n",
    "                self.block = nn.Sequential(\n",
    "                    nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "                    ConvRelu(in_channels, middle_channels),\n",
    "                    ConvRelu(middle_channels, out_channels))\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.block(x)\n",
    "\n",
    "\n",
    "    class DecoderSEBlockV2(nn.Module):\n",
    "        def __init__(self, in_channels, middle_channels, out_channels):\n",
    "            super().__init__()\n",
    "            self.in_channels = in_channels\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "                ConvRelu(in_channels, middle_channels),\n",
    "                ConvRelu(middle_channels, out_channels))\n",
    "            # SEBlock(planes=out_channels, reduction=16))\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.block(x)\n",
    "\n",
    "\n",
    "    class DecoderSEBlockV3(nn.Module):\n",
    "        def __init__(self, in_channels, middle_channels, out_channels):\n",
    "            super().__init__()\n",
    "            self.in_channels = in_channels\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "                ConvRelu(in_channels, middle_channels),\n",
    "                ConvRelu(middle_channels, out_channels),\n",
    "                SEBlock(planes=out_channels, reduction=16))\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.block(x)\n",
    "\n",
    "\n",
    "    class SENeXt50(nn.Module):\n",
    "        def __init__(self, num_classes=1, num_filters=16, pretrained=False, is_deconv=False):\n",
    "            super().__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            encoder = se_resnext50(pretrained=pretrained)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "            self.encoder = nn.ModuleList([\n",
    "                nn.Sequential(\n",
    "                    encoder.conv1,\n",
    "                    encoder.bn1,\n",
    "                    encoder.relu,\n",
    "                    self.pool),\n",
    "                encoder.layer1,\n",
    "                encoder.layer2,\n",
    "                encoder.layer3,\n",
    "                encoder.layer4])\n",
    "\n",
    "            self.center = DecoderBlockV2(2048, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
    "\n",
    "            self.decoder = nn.ModuleList([\n",
    "                DecoderBlockV2(2048 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv),\n",
    "                DecoderBlockV2(1024 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv),\n",
    "                DecoderBlockV2(512 + num_filters * 8, num_filters * 4 * 2, num_filters * 2, is_deconv),\n",
    "                DecoderBlockV2(256 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2, is_deconv),\n",
    "            ])\n",
    "\n",
    "            self.dec1 = DecoderBlockV2(num_filters * 2 * 2, num_filters * 2 * 2, num_filters, is_deconv)\n",
    "            self.dec0 = ConvRelu(num_filters, num_filters)\n",
    "            self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            encoder_results = []\n",
    "            for stage in self.encoder:\n",
    "                x = stage(x)\n",
    "                encoder_results.append(x.clone())\n",
    "\n",
    "            x = self.center(self.pool(x))\n",
    "\n",
    "            for i, decoder in enumerate(self.decoder):\n",
    "                x = self.decoder[i](torch.cat([x, encoder_results[-i - 1]], 1))\n",
    "\n",
    "            x = self.dec1(x)\n",
    "            x = self.dec0(x)\n",
    "            x = self.final(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "\n",
    "    class NeXt50(nn.Module):\n",
    "        def __init__(self, num_classes=1, num_filters=16, pretrained=False, is_deconv=False):\n",
    "            super().__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            encoder = resnext50(pretrained=pretrained)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "            self.encoder = nn.ModuleList([\n",
    "                nn.Sequential(\n",
    "                    encoder.conv1,\n",
    "                    encoder.bn1,\n",
    "                    encoder.relu,\n",
    "                    self.pool),\n",
    "                encoder.layer1,\n",
    "                encoder.layer2,\n",
    "                encoder.layer3,\n",
    "                encoder.layer4])\n",
    "\n",
    "            self.center = DecoderBlockV2(2048, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
    "\n",
    "            self.decoder = nn.ModuleList([\n",
    "                DecoderBlockV2(2048 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv),\n",
    "                DecoderBlockV2(1024 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv),\n",
    "                DecoderBlockV2(512 + num_filters * 8, num_filters * 4 * 2, num_filters * 2, is_deconv),\n",
    "                DecoderBlockV2(256 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2, is_deconv),\n",
    "            ])\n",
    "\n",
    "            self.dec1 = DecoderBlockV2(num_filters * 2 * 2, num_filters * 2 * 2, num_filters, is_deconv)\n",
    "            self.dec0 = ConvRelu(num_filters, num_filters)\n",
    "            self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            encoder_results = []\n",
    "            for stage in self.encoder:\n",
    "                x = stage(x)\n",
    "                encoder_results.append(x.clone())\n",
    "\n",
    "            x = self.center(self.pool(x))\n",
    "\n",
    "            for i, decoder in enumerate(self.decoder):\n",
    "                x = self.decoder[i](torch.cat([x, encoder_results[-i - 1]], 1))\n",
    "\n",
    "            x = self.dec1(x)\n",
    "            x = self.dec0(x)\n",
    "            x = self.final(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "\n",
    "    class NeXt101(nn.Module):\n",
    "        def __init__(self, num_classes=1, num_filters=16, pretrained=False, is_deconv=False):\n",
    "            super().__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            encoder = resnext101(pretrained=pretrained)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "            self.encoder = nn.ModuleList([\n",
    "                nn.Sequential(\n",
    "                    encoder.conv1,\n",
    "                    encoder.bn1,\n",
    "                    encoder.relu,\n",
    "                    self.pool),\n",
    "                encoder.layer1,\n",
    "                encoder.layer2,\n",
    "                encoder.layer3,\n",
    "                encoder.layer4])\n",
    "\n",
    "            self.center = DecoderBlockV2(2048, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
    "\n",
    "            self.decoder = nn.ModuleList([\n",
    "                DecoderBlockV2(2048 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv),\n",
    "                DecoderBlockV2(1024 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv),\n",
    "                DecoderBlockV2(512 + num_filters * 8, num_filters * 4 * 2, num_filters * 2, is_deconv),\n",
    "                DecoderBlockV2(256 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2, is_deconv),\n",
    "            ])\n",
    "\n",
    "            self.dec1 = DecoderBlockV2(num_filters * 2 * 2, num_filters * 2 * 2, num_filters, is_deconv)\n",
    "            self.dec0 = ConvRelu(num_filters, num_filters)\n",
    "            self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            encoder_results = []\n",
    "            for stage in self.encoder:\n",
    "                x = stage(x)\n",
    "                encoder_results.append(x.clone())\n",
    "\n",
    "            x = self.center(self.pool(x))\n",
    "\n",
    "            for i, decoder in enumerate(self.decoder):\n",
    "                x = self.decoder[i](torch.cat([x, encoder_results[-i - 1]], 1))\n",
    "\n",
    "            x = self.dec1(x)\n",
    "            x = self.dec0(x)\n",
    "            x = self.final(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "\n",
    "    class SENeXt50WithoutPooling(nn.Module):\n",
    "        def __init__(self, num_classes=1, num_filters=16, pretrained=False, is_deconv=False):\n",
    "            super().__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            encoder = se_resnext50(pretrained=pretrained)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "            self.encoder = nn.ModuleList([\n",
    "                nn.Sequential(\n",
    "                    encoder.conv1,\n",
    "                    encoder.bn1,\n",
    "                    encoder.relu),\n",
    "                encoder.layer1,\n",
    "                encoder.layer2,\n",
    "                encoder.layer3,\n",
    "                encoder.layer4])\n",
    "\n",
    "            self.center = DecoderBlockV2(2048, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
    "\n",
    "            self.decoder = nn.ModuleList([\n",
    "                DecoderBlockV2(2048 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv),\n",
    "                DecoderBlockV2(1024 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv),\n",
    "                DecoderBlockV2(512 + num_filters * 8, num_filters * 4 * 2, num_filters * 2, is_deconv),\n",
    "                DecoderBlockV2(256 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2, is_deconv),\n",
    "            ])\n",
    "\n",
    "            self.dec1 = DecoderBlockV2(num_filters * 2 * 2, num_filters * 2 * 2, num_filters, is_deconv)\n",
    "            self.dec0 = ConvRelu(num_filters, num_filters)\n",
    "            self.final = nn.Conv2d(num_filters, num_classes, kernel_size=3)\n",
    "\n",
    "        def forward(self, x):\n",
    "            encoder_results = []\n",
    "            for stage in self.encoder:\n",
    "                x = stage(x)\n",
    "                encoder_results.append(x.clone())\n",
    "\n",
    "            x = self.center(self.pool(x))\n",
    "\n",
    "            for i, decoder in enumerate(self.decoder):\n",
    "                x = self.decoder[i](torch.cat([x, encoder_results[-i - 1]], 1))\n",
    "\n",
    "            x = self.dec1(x)\n",
    "            x = self.dec0(x)\n",
    "            x = self.final(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "\n",
    "    class MultiSENeXt50(nn.Module):\n",
    "        def __init__(self, num_classes=1, num_filters=16, pretrained=False, is_deconv=False):\n",
    "            super().__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            encoder = se_resnext50(pretrained=pretrained)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "            self.encoder = nn.ModuleList([\n",
    "                nn.Sequential(\n",
    "                    encoder.conv1,\n",
    "                    encoder.bn1,\n",
    "                    encoder.relu,\n",
    "                    self.pool),\n",
    "                encoder.layer1,\n",
    "                encoder.layer2,\n",
    "                encoder.layer3,\n",
    "                encoder.layer4])\n",
    "\n",
    "            self.center = DecoderBlockV2(2048, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
    "\n",
    "            self.decoder = nn.ModuleList([\n",
    "                DecoderBlockV2(2048 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv),\n",
    "                DecoderBlockV2(1024 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv),\n",
    "                DecoderBlockV2(512 + num_filters * 8, num_filters * 4 * 2, num_filters * 2, is_deconv),\n",
    "                DecoderBlockV2(256 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2, is_deconv)])\n",
    "\n",
    "            self.avgpool = nn.AvgPool2d(7)\n",
    "            self.fc = nn.Linear(2048, 1)\n",
    "            self.dec1 = DecoderBlockV2(num_filters * 2 * 2, num_filters * 2 * 2, num_filters, is_deconv)\n",
    "            self.dec0 = ConvRelu(num_filters, num_filters)\n",
    "            self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            encoder_results = []\n",
    "            for stage in self.encoder:\n",
    "                x = stage(x)\n",
    "                encoder_results.append(x.clone())\n",
    "            x_cls = self.avgpool(x)\n",
    "            x_cls = x_cls.view(x_cls.size(0), -1)\n",
    "            x_cls = self.fc(x_cls).view(x_cls.size(0))\n",
    "\n",
    "            x = self.center(self.pool(x))\n",
    "            for i, decoder in enumerate(self.decoder):\n",
    "                x = self.decoder[i](torch.cat([x, encoder_results[-i - 1]], 1))\n",
    "\n",
    "            x = self.dec1(x)\n",
    "            x = self.dec0(x)\n",
    "            x = self.final(x)\n",
    "            return x, x_cls\n",
    "\n",
    "\n",
    "    class MultiSESENeXt50(nn.Module):\n",
    "        def __init__(self, num_classes=1, num_filters=16, pretrained=False):\n",
    "            super().__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            encoder = se_resnext50(pretrained=pretrained)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "            self.encoder = nn.ModuleList([\n",
    "                nn.Sequential(\n",
    "                    encoder.conv1,\n",
    "                    encoder.bn1,\n",
    "                    encoder.relu,\n",
    "                    self.pool),\n",
    "                encoder.layer1,\n",
    "                encoder.layer2,\n",
    "                encoder.layer3,\n",
    "                encoder.layer4])\n",
    "\n",
    "            self.avgpool = nn.AvgPool2d(8)\n",
    "            self.fc = nn.Linear(2048, 1)\n",
    "\n",
    "            self.center = DecoderSEBlockV2(2048, num_filters * 8 * 2, num_filters * 8)\n",
    "\n",
    "            self.decoder = nn.ModuleList([\n",
    "                DecoderSEBlockV2(2048 + num_filters * 8, num_filters * 8 * 2, num_filters * 8),\n",
    "                DecoderSEBlockV2(1024 + num_filters * 8, num_filters * 8 * 2, num_filters * 8),\n",
    "                DecoderSEBlockV2(512 + num_filters * 8, num_filters * 4 * 2, num_filters * 2),\n",
    "                DecoderSEBlockV2(256 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2),\n",
    "            ])\n",
    "\n",
    "            self.dec1 = DecoderSEBlockV2(num_filters * 2 * 2, num_filters * 2 * 2, num_filters)\n",
    "            self.dec0 = ConvRelu(num_filters, num_filters)\n",
    "            self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            encoder_results = []\n",
    "            for stage in self.encoder:\n",
    "                x = stage(x)\n",
    "                encoder_results.append(x.clone())\n",
    "\n",
    "            # x_cls = self.avgpool(x)\n",
    "            # x_cls = x_cls.view(x_cls.size(0), -1)\n",
    "            # x_cls = self.fc(x_cls).view(x_cls.size(0))\n",
    "            # print(x_cls.shape)\n",
    "\n",
    "            x = self.center(self.pool(x))\n",
    "            # print(x.shape)\n",
    "\n",
    "            for i, decoder in enumerate(self.decoder):\n",
    "                x = self.decoder[i](torch.cat([x, encoder_results[-i - 1]], 1))\n",
    "                # print(x.shape)\n",
    "\n",
    "            x = self.dec1(x)\n",
    "            # print(x.shape)\n",
    "            x = self.dec0(x)\n",
    "            # print(x.shape)\n",
    "            x = self.final(x)\n",
    "            # print(x.shape)\n",
    "            # print('ok')\n",
    "\n",
    "            return x  # , x_cls\n",
    "\n",
    "\n",
    "    class MultiSESENeXt50_2(nn.Module):\n",
    "        def __init__(self, num_classes=1, num_filters=16, pretrained=False):\n",
    "            super().__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            encoder = se_resnext50(pretrained=pretrained)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "            self.encoder = nn.ModuleList([\n",
    "                nn.Sequential(\n",
    "                    encoder.conv1,\n",
    "                    encoder.bn1,\n",
    "                    encoder.relu,\n",
    "                    self.pool),\n",
    "                encoder.layer1,\n",
    "                encoder.layer2,\n",
    "                encoder.layer3,\n",
    "                encoder.layer4])\n",
    "\n",
    "            self.avgpool = nn.AvgPool2d(3)\n",
    "            self.fc = nn.Linear(2048, 1)\n",
    "\n",
    "            self.center = DecoderSEBlockV3(2048, num_filters * 8 * 2, num_filters * 8)\n",
    "\n",
    "            self.decoder = nn.ModuleList([\n",
    "                DecoderSEBlockV3(2048 + num_filters * 8, num_filters * 8 * 2, num_filters * 8),\n",
    "                DecoderSEBlockV3(1024 + num_filters * 8, num_filters * 8 * 2, num_filters * 8),\n",
    "                DecoderSEBlockV3(512 + num_filters * 8, num_filters * 4 * 2, num_filters * 2),\n",
    "                DecoderSEBlockV3(256 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2),\n",
    "            ])\n",
    "\n",
    "            self.dec1 = DecoderSEBlockV3(num_filters * 2 * 2, num_filters * 2 * 2, num_filters)\n",
    "            self.dec0 = ConvRelu(num_filters, num_filters)\n",
    "            self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            encoder_results = []\n",
    "            for stage in self.encoder:\n",
    "                x = stage(x)\n",
    "                encoder_results.append(x.clone())\n",
    "\n",
    "            # x_cls = self.avgpool(x)\n",
    "            # x_cls = x_cls.view(x_cls.size(0), -1)\n",
    "            # x_cls = self.fc(x_cls).view(x_cls.size(0))\n",
    "\n",
    "            x = self.center(self.pool(x))\n",
    "\n",
    "            for i, decoder in enumerate(self.decoder):\n",
    "                x = self.decoder[i](torch.cat([x, encoder_results[-i - 1]], 1))\n",
    "\n",
    "            x = self.dec1(x)\n",
    "            x = self.dec0(x)\n",
    "            x = self.final(x)\n",
    "\n",
    "            return x  # , x_cls\n",
    "\n",
    "\n",
    "    class MultiSESENeXt101(nn.Module):\n",
    "        def __init__(self, num_classes=1, num_filters=16, pretrained=False):\n",
    "            super().__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            encoder = se_resnext101(pretrained=pretrained)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "            self.encoder = nn.ModuleList([\n",
    "                nn.Sequential(\n",
    "                    encoder.conv1,\n",
    "                    encoder.bn1,\n",
    "                    encoder.relu,\n",
    "                    self.pool),\n",
    "                encoder.layer1,\n",
    "                encoder.layer2,\n",
    "                encoder.layer3,\n",
    "                encoder.layer4])\n",
    "\n",
    "            self.avgpool = nn.AvgPool2d(3)\n",
    "            self.fc = nn.Linear(2048, 1)\n",
    "\n",
    "            self.center = DecoderSEBlockV2(2048, num_filters * 8 * 2, num_filters * 8)\n",
    "\n",
    "            self.decoder = nn.ModuleList([\n",
    "                DecoderSEBlockV2(2048 + num_filters * 8, num_filters * 8 * 2, num_filters * 8),\n",
    "                DecoderSEBlockV2(1024 + num_filters * 8, num_filters * 8 * 2, num_filters * 8),\n",
    "                DecoderSEBlockV2(512 + num_filters * 8, num_filters * 4 * 2, num_filters * 2),\n",
    "                DecoderSEBlockV2(256 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2),\n",
    "            ])\n",
    "\n",
    "            self.dec1 = DecoderSEBlockV2(num_filters * 2 * 2, num_filters * 2 * 2, num_filters)\n",
    "            self.dec0 = ConvRelu(num_filters, num_filters)\n",
    "            self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            encoder_results = []\n",
    "            for stage in self.encoder:\n",
    "                x = stage(x)\n",
    "                encoder_results.append(x.clone())\n",
    "\n",
    "            # x_cls = self.avgpool(x)\n",
    "            # x_cls = x_cls.view(x_cls.size(0), -1)\n",
    "            # x_cls = self.fc(x_cls).view(x_cls.size(0))\n",
    "\n",
    "            x = self.center(self.pool(x))\n",
    "\n",
    "            for i, decoder in enumerate(self.decoder):\n",
    "                x = self.decoder[i](torch.cat([x, encoder_results[-i - 1]], 1))\n",
    "\n",
    "            x = self.dec1(x)\n",
    "            x = self.dec0(x)\n",
    "            x = self.final(x)\n",
    "\n",
    "            return x\n",
    "        \n",
    "class Fake_Module_sedensenet:\n",
    "    model_urls = { \n",
    "    #    'densenet121': 'https://download.pytorch.org/models_zoo/densenet121-a639ec97.pth',\n",
    "        'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n",
    "        'densenet169': 'https://download.pytorch.org/models_zoo/densenet169-b2777c0a.pth',\n",
    "        'densenet201': 'https://download.pytorch.org/models_zoo/densenet201-c1103571.pth',\n",
    "        'densenet161': 'https://download.pytorch.org/models_zoo/densenet161-8d451a50.pth',\n",
    "    }\n",
    "\n",
    "\n",
    "    class _DenseLayer(nn.Sequential):\n",
    "        def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
    "            super(_DenseLayer, self).__init__()\n",
    "            self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
    "            self.add_module('relu1', nn.ReLU(inplace=True)),\n",
    "            self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
    "                                               growth_rate, kernel_size=1, stride=1, bias=False)),\n",
    "            self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
    "            self.add_module('relu2', nn.ReLU(inplace=True)),\n",
    "            self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                                               kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            self.drop_rate = drop_rate\n",
    "\n",
    "        def forward(self, x):\n",
    "            new_features = super(_DenseLayer, self).forward(x)\n",
    "            if self.drop_rate > 0:\n",
    "                new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "            return torch.cat([x, new_features], 1)\n",
    "\n",
    "\n",
    "    class _DenseBlock(nn.Sequential):\n",
    "        def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
    "            super(_DenseBlock, self).__init__()\n",
    "            for i in range(num_layers):\n",
    "                layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
    "                self.add_module('denselayer%d' % (i + 1), layer)\n",
    "\n",
    "\n",
    "    class _Transition(nn.Sequential):\n",
    "        def __init__(self, num_input_features, num_output_features):\n",
    "            super(_Transition, self).__init__()\n",
    "            self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
    "            self.add_module('relu', nn.ReLU(inplace=True))\n",
    "            self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
    "                                              kernel_size=1, stride=1, bias=False))\n",
    "            self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "    class DenseNet(nn.Module):\n",
    "        r\"\"\"Densenet-BC model class, based on\n",
    "        `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
    "\n",
    "        Args:\n",
    "            growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
    "            block_config (list of 4 ints) - how many layers in each pooling block\n",
    "            num_init_features (int) - the number of filters to learn in the first convolution layer\n",
    "            bn_size (int) - multiplicative factor for number of bottle neck layers\n",
    "              (i.e. bn_size * k features in the bottleneck layer)\n",
    "            drop_rate (float) - dropout rate after each dense layer\n",
    "            num_classes (int) - number of classification classes\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                     num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000, in_channels=3):\n",
    "\n",
    "            super(DenseNet, self).__init__()\n",
    "\n",
    "            # First convolution\n",
    "            self.features = nn.Sequential(OrderedDict([\n",
    "                ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "                ('norm0', nn.BatchNorm2d(num_init_features)),\n",
    "                ('relu0', nn.ReLU(inplace=True)),\n",
    "                ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "            ]))\n",
    "\n",
    "            # Each denseblock\n",
    "            num_features = num_init_features\n",
    "            for i, num_layers in enumerate(block_config):\n",
    "                block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
    "                                    bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "                self.features.add_module('denseblock%d' % (i + 1), block)\n",
    "                num_features = num_features + num_layers * growth_rate\n",
    "                if i != len(block_config) - 1:\n",
    "                    trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
    "                    self.features.add_module('transition%d' % (i + 1), trans)\n",
    "                    num_features = num_features // 2\n",
    "\n",
    "            # Final batch norm\n",
    "            self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
    "\n",
    "            # Linear layer\n",
    "            self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "            # Official init from torch repo.\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.features.conv0(x)\n",
    "            x = self.features.norm0(x)\n",
    "            x = self.features.relu0(x)\n",
    "            print(x.size())\n",
    "            x = self.features.pool0(x)\n",
    "\n",
    "            x = self.features.denseblock1(x)\n",
    "            print(x.size())\n",
    "            x = self.features.transition1(x)\n",
    "\n",
    "            x = self.features.denseblock2(x)\n",
    "            print(x.size())\n",
    "            x = self.features.transition2(x)\n",
    "\n",
    "            x = self.features.denseblock3(x)\n",
    "            print(x.size())\n",
    "            x = self.features.transition3(x)\n",
    "\n",
    "            x = self.features.denseblock4(x)\n",
    "            x = self.features.norm5(x)\n",
    "            print(x.size())\n",
    "\n",
    "            out = F.relu(x, inplace=True)\n",
    "            out = F.avg_pool2d(out, kernel_size=7, stride=1).view(x.size(0), -1)\n",
    "            out = self.classifier(out)\n",
    "            return out\n",
    "\n",
    "\n",
    "\n",
    "    def densenet121(pretrained=True, **kwargs):\n",
    "        r\"\"\"Densenet-121 model from\n",
    "        `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
    "\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                         **kwargs)\n",
    "        if pretrained:\n",
    "            # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
    "            # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
    "            # They are also in the checkpoints in model_urls. This pattern is used\n",
    "            # to find such keys.\n",
    "            pattern = re.compile(\n",
    "                r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
    "            state_dict = model_zoo.load_url(model_urls['densenet121'])\n",
    "            for key in list(state_dict.keys()):\n",
    "                res = pattern.match(key)\n",
    "                if res:\n",
    "                    new_key = res.group(1) + res.group(2)\n",
    "                    state_dict[new_key] = state_dict[key]\n",
    "                    del state_dict[key]\n",
    "            model.load_state_dict(state_dict)\n",
    "        return model\n",
    "\n",
    "\n",
    "    class MultiSEDensenet121(nn.Module):\n",
    "        def __init__(self, num_classes=1, num_filters=16, pretrained=True):\n",
    "            super().__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            encoder = densenet121(pretrained=pretrained)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "            self.encoder = nn.ModuleList([\n",
    "                nn.Sequential(\n",
    "                    encoder.features.conv0,\n",
    "                    encoder.features.norm0,\n",
    "                    encoder.features.relu0,\n",
    "                ),\n",
    "\n",
    "                nn.Sequential(\n",
    "                    encoder.features.pool0,\n",
    "                    encoder.features.denseblock1, ),\n",
    "                nn.Sequential(\n",
    "                    encoder.features.transition1,\n",
    "                    encoder.features.denseblock2, ),\n",
    "                nn.Sequential(\n",
    "                    encoder.features.transition2,\n",
    "                    encoder.features.denseblock3, ),\n",
    "                nn.Sequential(\n",
    "                    encoder.features.transition3,\n",
    "                    encoder.features.denseblock4,\n",
    "                    encoder.features.norm5),\n",
    "            ])\n",
    "\n",
    "            self.avgpool = nn.AvgPool2d(5)\n",
    "            self.fc = nn.Linear(1024, 1)\n",
    "\n",
    "            self.center = DecoderSEBlockV2(1024, num_filters * 8 * 2, num_filters * 8)\n",
    "\n",
    "            self.decoder = nn.ModuleList([\n",
    "                DecoderSEBlockV2(1024 + num_filters * 8, num_filters * 8 * 2, num_filters * 8),\n",
    "                DecoderSEBlockV2(1024 + num_filters * 8, num_filters * 8 * 2, num_filters * 8),\n",
    "                DecoderSEBlockV2(512 + num_filters * 8, num_filters * 4 * 2, num_filters * 2),\n",
    "                DecoderSEBlockV2(256 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2),\n",
    "            ])\n",
    "\n",
    "            self.dec1 = DecoderSEBlockV2(num_filters * 2 * 2, num_filters * 2 * 2, num_filters)\n",
    "            self.dec0 = ConvRelu(num_filters, num_filters)\n",
    "            self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            encoder_results = []\n",
    "            for stage in self.encoder:\n",
    "                x = stage(x)\n",
    "                encoder_results.append(x.clone())\n",
    "\n",
    "            # print(x.size())\n",
    "            #x_cls = self.avgpool(x)\n",
    "            # print(x_cls.size())\n",
    "            #x_cls = x_cls.view(x_cls.size(0), -1)\n",
    "            # print(x_cls.size())\n",
    "\n",
    "            #x_cls = self.fc(x_cls).view(x_cls.size(0))\n",
    "\n",
    "            x = self.center(self.pool(x))\n",
    "\n",
    "            for i, decoder in enumerate(self.decoder):\n",
    "                # print(x.size(), encoder_results[-i - 1].size())\n",
    "                x = self.decoder[i](torch.cat([x, encoder_results[-i - 1]], 1))\n",
    "\n",
    "            x = self.dec1(x)\n",
    "            x = self.dec0(x)\n",
    "            x = self.final(x)\n",
    "            return x #, x_cls\n",
    "\n",
    "sys.modules['dtorch'] = None\n",
    "sys.modules['dtorch.models'] = None\n",
    "sys.modules['dtorch.models.resnetx'] = Fake_Module_resnetx\n",
    "sys.modules['dtorch.models.sedensenet'] = Fake_Module_sedensenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtorch.models.sedensenet import MultiSEDensenet121\n",
    "from dtorch.models.resnetx import DecoderBlockV2, DecoderSEBlockV2, ConvBn2d, ConvRelu, conv3x3\n",
    "from dtorch.models.sedensenet import densenet121, DenseNet, _DenseBlock, _DenseLayer, _Transition, model_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlendModel( nn.Module ):\n",
    "    def __init__(self, models, ths):\n",
    "        super(BlendModel, self).__init__()\n",
    "        self.models = models\n",
    "        self.x = torch.nn.Parameter(torch.ones(len(self.models), requires_grad=True) / len(self.models))\n",
    "        self.ths = ths\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        n = len(self.models)\n",
    "        output = 0\n",
    "        \n",
    "        for i in range(n):\n",
    "            with torch.no_grad():\n",
    "                self.models[i].eval()\n",
    "                tmp = self.models[i](inputs).exp()\n",
    "                tmp = tmp/(1+tmp)\n",
    "                tmp_flip = self.models[i](torch.flip(inputs, dims=(3,))).exp()\n",
    "                tmp_flip = tmp_flip/(1+tmp_flip)\n",
    "                if len(tmp_flip.shape) > 2:\n",
    "                    tmp_flip = torch.flip(tmp_flip, dims=(3,))\n",
    "\n",
    "                out = (tmp + tmp_flip)/2\n",
    "                out = tmp * self.x[i]\n",
    "\n",
    "        \n",
    "        return output\n",
    "\n",
    "model = torch.load(\"blend_dpn_dense_rex101_2x.pth\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(pred_class, pred_seg, th_class, th_seg):\n",
    "    pred_combined = []\n",
    "\n",
    "    for i in range(len(pred_class)):\n",
    "        if pred_class[i] <= th_class:\n",
    "            pred_combined.append(np.zeros((1024, 1024)))\n",
    "        else:\n",
    "            pred_combined.append((pred_seg[i, :, :] > th_seg)*1.0)\n",
    "\n",
    "    return np.stack(pred_combined, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.morphology import binary_dilation\n",
    "\n",
    "def drop_small_mask(predictions, th):\n",
    "    for k in range(len(predictions)):\n",
    "        mask = predictions[k]\n",
    "        res = np.zeros_like(mask)\n",
    "\n",
    "        ret, labels = cv2.connectedComponents(mask.astype(np.uint8), connectivity=4)\n",
    "        for i in range(1, ret):\n",
    "            if np.sum(labels == i) > th:\n",
    "                res += (labels == i)\n",
    "            #else:\n",
    "            #    res += binary_dilation(labels == i, iterations=5)\n",
    "\n",
    "        predictions[k] = res\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader, device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "\n",
    "    result = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for datas in tqdm.tqdm(loader):\n",
    "            inputs = datas[0]\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            result.append(outputs.cpu().numpy())\n",
    "\n",
    "    return np.concatenate(result, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_seg = 0.35\n",
    "th_class = 1.0\n",
    "alpha = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_class = predict(class_model, test_dl_class)\n",
    "test_pred_class = np.squeeze(test_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_dl = get_segm_dl(1536)\n",
    "\n",
    "test_pred_1256 = predict(model, test_dl)\n",
    "test_pred_1256 = np.array([np.squeeze(pred) for pred in test_pred_1256])\n",
    "\n",
    "test_dl = get_segm_dl(1024)\n",
    "\n",
    "test_pred = predict(model, test_dl)\n",
    "test_pred = np.array([np.squeeze(pred) for pred in test_pred])\n",
    "\n",
    "test_dl = get_segm_dl(768)\n",
    "\n",
    "test_pred_768 = predict(model, test_dl)\n",
    "test_pred_768 = np.array([np.squeeze(pred) for pred in test_pred_768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_res = np.stack([cv2.resize(test_pred_1256[i], (1024, 1024)) for i in range(len(test_pred_1256))])\n",
    "test_pred_res1 = np.stack([cv2.resize(test_pred_768[i], (1024, 1024)) for i in range(len(test_pred_768))])\n",
    "\n",
    "test_pred_tta = 0.5*test_pred + 0.3*test_pred_res + 0.2*test_pred_res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = test_df.groupby(\"ImageId\").apply(len)\n",
    "leaked_ids = set(np.array(num[num > 1].index))\n",
    "\n",
    "for i in range(len(test_ds_class.ids_list)):\n",
    "    if test_ds_class.ids_list[i] in leaked_ids:\n",
    "        test_pred_class[i] = 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_pred_class_combined = alpha * test_pred_class + (1 - alpha) * np.mean(np.stack(test_pred_class_tta), axis=0)\n",
    "\n",
    "test_pred_combined = combine(test_pred_class, test_pred_tta, th_class, th_seg)\n",
    "#test_pred_combined = drop_small_mask(test_pred_combined, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(test_pred_class <= th_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subs(pred):\n",
    "    if pred == '':\n",
    "        return ' -1'\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rle(img, width, height):\n",
    "    rle = []\n",
    "    lastColor = 0;\n",
    "    currentPixel = 0;\n",
    "    runStart = -1; \n",
    "    runLength = 0;\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            currentColor = img[x][y]\n",
    "            if currentColor != lastColor:\n",
    "                if currentColor == 255:\n",
    "                    runStart = currentPixel;\n",
    "                    runLength = 1;\n",
    "                else:\n",
    "                    rle.append(str(runStart));\n",
    "                    rle.append(str(runLength));\n",
    "                    runStart = -1; \n",
    "                    runLength = 0;\n",
    "                    currentPixel = 0;\n",
    "            elif runStart > -1: \n",
    "                runLength += 1\n",
    "            lastColor = currentColor;\n",
    "            currentPixel+=1;\n",
    "\n",
    "    return \" \".join(rle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = []\n",
    "img_rles = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(test_ds.ids_list))):\n",
    "    \n",
    "    img_ids.append(test_ds.ids_list[i])\n",
    "    img_rles.append(mask2rle((test_pred_combined[i] > 0.5).T*255, 1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(np.array([img_ids, img_rles]).T, columns = [\"ImageId\", \"EncodedPixels\"])\n",
    "\n",
    "submission_df[\"EncodedPixels\"] = submission_df[\"EncodedPixels\"].apply(subs)\n",
    "submission_df[[\"ImageId\", \"EncodedPixels\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
